# LiteLLM MCP Server Configuration
# Copy this file to .env and update with your values

# LiteLLM Proxy Configuration
# URL of your LiteLLM proxy server
LITELLM_PROXY_URL=https://litellm.shared-services.adb.adi.tech

# API Keys for the LiteLLM proxy
# Use the API key provided by your LiteLLM proxy service
LITELLM_API_KEY=sk-jhBs4H8kSBGagA7e179rkw

# Optional: OpenAI API key (if needed for specific models)
# OPENAI_API_KEY=your_openai_api_key_here

# Performance Optimization Settings
# HTTP Client Settings
HTTP_TIMEOUT=30.0
HTTP_CONNECT_TIMEOUT=10.0
HTTP_MAX_KEEPALIVE_CONNECTIONS=20
HTTP_MAX_CONNECTIONS=100
HTTP_ENABLE_HTTP2=true

# LiteLLM Request Settings
LITELLM_REQUEST_TIMEOUT=60.0
LITELLM_MAX_RETRIES=3
LITELLM_RETRY_DELAY=1.0

# Performance Monitoring
LOG_PERFORMANCE_METRICS=true
LOG_SLOW_QUERIES_THRESHOLD=5.0

# Caching Settings (for future use)
ENABLE_RESPONSE_CACHING=false
CACHE_TTL_SECONDS=300
CACHE_MAX_SIZE=1000 